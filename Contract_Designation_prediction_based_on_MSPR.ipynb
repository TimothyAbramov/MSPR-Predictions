{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxpAq1UchwIJ",
        "outputId": "67088e17-337a-4ab4-a19e-1b11e12799ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJp3hEwvuBCc"
      },
      "source": [
        "**Putting data together**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-CfDbUMh7gU",
        "outputId": "f531f729-9b4b-4ec4-f4ab-d6ab559111a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ATTENDANCE  LOW PARTICIPATION  LATE/MISSING ASSIGNMENTS  \\\n",
            "0           0                  0                         0   \n",
            "1           0                  0                         0   \n",
            "2           0                  0                         0   \n",
            "3           0                  0                         0   \n",
            "4           1                  0                         0   \n",
            "\n",
            "   OTHER ASSIGNMENTS CONCERNS  LOW TEST SCORES  DANGER of UNSATING  \\\n",
            "0                           0                0                   0   \n",
            "1                           0                1                   1   \n",
            "2                           0                0                   0   \n",
            "3                           0                0                   0   \n",
            "4                           0                0                   0   \n",
            "\n",
            "   DESIGNATION_BINARY  \n",
            "0                   1  \n",
            "1                   1  \n",
            "2                   1  \n",
            "3                   1  \n",
            "4                   0  \n"
          ]
        }
      ],
      "source": [
        "# prompt: import a .csv dataset\n",
        "\n",
        "import pandas as pd\n",
        "mvp_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DL Fall 2024/MSPR predictions/datasets/mvp_train(all terms).csv')\n",
        "print(mvp_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDyQvr1L7mQM",
        "outputId": "2dbeea59-f71f-4341-cb43-1d00c0009f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4530 entries, 0 to 4529\n",
            "Data columns (total 7 columns):\n",
            " #   Column                      Non-Null Count  Dtype\n",
            "---  ------                      --------------  -----\n",
            " 0   ATTENDANCE                  4530 non-null   int64\n",
            " 1   LOW PARTICIPATION           4530 non-null   int64\n",
            " 2   LATE/MISSING ASSIGNMENTS    4530 non-null   int64\n",
            " 3   OTHER ASSIGNMENTS CONCERNS  4530 non-null   int64\n",
            " 4   LOW TEST SCORES             4530 non-null   int64\n",
            " 5   DANGER of UNSATING          4530 non-null   int64\n",
            " 6   DESIGNATION_BINARY          4530 non-null   int64\n",
            "dtypes: int64(7)\n",
            "memory usage: 247.9 KB\n"
          ]
        }
      ],
      "source": [
        "mvp_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksymMAIiBEGJ",
        "outputId": "47e77dae-0b16-4f51-bdea-b6d680dc0b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution for column: ATTENDANCE\n",
            "            Count  Percentage\n",
            "ATTENDANCE                   \n",
            "0            3913   86.379691\n",
            "1             441    9.735099\n",
            "2             117    2.582781\n",
            "3              48    1.059603\n",
            "4              10    0.220751\n",
            "5               1    0.022075\n",
            "--------------------\n",
            "Distribution for column: LOW PARTICIPATION\n",
            "                   Count  Percentage\n",
            "LOW PARTICIPATION                   \n",
            "0                   3881   85.673289\n",
            "1                    529   11.677704\n",
            "2                     98    2.163355\n",
            "3                     22    0.485651\n",
            "--------------------\n",
            "Distribution for column: LATE/MISSING ASSIGNMENTS\n",
            "                          Count  Percentage\n",
            "LATE/MISSING ASSIGNMENTS                   \n",
            "0                          3331   73.532009\n",
            "1                           791   17.461369\n",
            "2                           281    6.203091\n",
            "3                           109    2.406181\n",
            "4                            17    0.375276\n",
            "5                             1    0.022075\n",
            "--------------------\n",
            "Distribution for column: OTHER ASSIGNMENTS CONCERNS\n",
            "                            Count  Percentage\n",
            "OTHER ASSIGNMENTS CONCERNS                   \n",
            "0                            4041   89.205298\n",
            "1                             435    9.602649\n",
            "2                              48    1.059603\n",
            "3                               6    0.132450\n",
            "--------------------\n",
            "Distribution for column: LOW TEST SCORES\n",
            "                 Count  Percentage\n",
            "LOW TEST SCORES                   \n",
            "0                 3850   84.988962\n",
            "1                  554   12.229581\n",
            "2                  116    2.560706\n",
            "3                   10    0.220751\n",
            "--------------------\n",
            "Distribution for column: DANGER of UNSATING\n",
            "                    Count  Percentage\n",
            "DANGER of UNSATING                   \n",
            "0                    3849   84.966887\n",
            "1                     495   10.927152\n",
            "2                     132    2.913907\n",
            "3                      45    0.993377\n",
            "4                       8    0.176600\n",
            "5                       1    0.022075\n",
            "--------------------\n",
            "Distribution for column: DESIGNATION_BINARY\n",
            "                    Count  Percentage\n",
            "DESIGNATION_BINARY                   \n",
            "1                    4113   90.794702\n",
            "0                     417    9.205298\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "# prompt: show distributions for fields in the mvp_df, show distributions in terms of count and percentage\n",
        "\n",
        "# Calculate counts and percentages for each column\n",
        "for col in mvp_df.columns:\n",
        "  print(f\"Distribution for column: {col}\")\n",
        "  counts = mvp_df[col].value_counts()\n",
        "  percentages = (counts / len(mvp_df)) * 100\n",
        "  distribution_df = pd.DataFrame({'Count': counts, 'Percentage': percentages})\n",
        "  print(distribution_df)\n",
        "  print(\"-\" * 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdDVChsuudys"
      },
      "source": [
        "**Stratified sampling for train, val, and test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yc_A-_6BszT",
        "outputId": "9abf0cb6-8165-47ba-f593-91568021e7a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (3171, 7)\n",
            "Validation set shape: (679, 7)\n",
            "Test set shape: (680, 7)\n"
          ]
        }
      ],
      "source": [
        "# prompt: Split mvp_df into train, validation, and test. Use stratified splitting to maintain class balance across sets.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, temp_df = train_test_split(mvp_df, test_size=0.3, stratify=mvp_df['DESIGNATION_BINARY'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['DESIGNATION_BINARY'], random_state=42)\n",
        "\n",
        "print(\"Train set shape:\", train_df.shape)\n",
        "print(\"Validation set shape:\", val_df.shape)\n",
        "print(\"Test set shape:\", test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75ZxXfnRu4gY",
        "outputId": "e45d9ef5-36c5-4ec0-f54e-66cbebdcae4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution for train_df:\n",
            "                    Count  Percentage\n",
            "DESIGNATION_BINARY                   \n",
            "1                    2879   90.791548\n",
            "0                     292    9.208452\n",
            "--------------------\n",
            "Distribution for val_df:\n",
            "                    Count  Percentage\n",
            "DESIGNATION_BINARY                   \n",
            "1                     617   90.868925\n",
            "0                      62    9.131075\n",
            "--------------------\n",
            "Distribution for test_df:\n",
            "                    Count  Percentage\n",
            "DESIGNATION_BINARY                   \n",
            "1                     617   90.735294\n",
            "0                      63    9.264706\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "# prompt: Show distributions of DESIGNATION_BINARY in train_df, val_df, and test_df\n",
        "\n",
        "def show_distribution(df, name):\n",
        "    print(f\"Distribution for {name}:\")\n",
        "    counts = df['DESIGNATION_BINARY'].value_counts()\n",
        "    percentages = (counts / len(df)) * 100\n",
        "    distribution_df = pd.DataFrame({'Count': counts, 'Percentage': percentages})\n",
        "    print(distribution_df)\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "show_distribution(train_df, \"train_df\")\n",
        "show_distribution(val_df, \"val_df\")\n",
        "show_distribution(test_df, \"test_df\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lrSnJtAqCzxI"
      },
      "outputs": [],
      "source": [
        "# prompt: Split train_df into X_train and y_train. Split val_df into X_val and y_val. Split test_df into X_test and y_test.\n",
        "\n",
        "X_train = train_df.drop('DESIGNATION_BINARY', axis=1)\n",
        "y_train = train_df['DESIGNATION_BINARY']\n",
        "\n",
        "X_val = val_df.drop('DESIGNATION_BINARY', axis=1)\n",
        "y_val = val_df['DESIGNATION_BINARY']\n",
        "\n",
        "X_test = test_df.drop('DESIGNATION_BINARY', axis=1)\n",
        "y_test = test_df['DESIGNATION_BINARY']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmuhUT5HuNNS"
      },
      "source": [
        "**Standartization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "veYpwX1HuA2k"
      },
      "outputs": [],
      "source": [
        "# prompt: Standardize X_train. Then standardize X_val and X_test. Use from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on X_train and transform\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform X_val and X_test using the same scaler\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P90Y_LmiuOlt",
        "outputId": "88ea10e9-249b-468e-bbb7-34d7fbf72e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of X_train_scaled: 0.0\n",
            "Standard deviation of X_train_scaled: 1.0\n",
            "Mean of X_val_scaled: 0.041313408948414024\n",
            "Standard deviation of X_val_scaled: 1.0678334789113186\n",
            "Mean of X_test_scaled: 0.027231254798653758\n",
            "Standard deviation of X_test_scaled: 1.0407539151632823\n"
          ]
        }
      ],
      "source": [
        "# prompt: Print mean and std of X_train_scaled, X_val_scaled, and X_test_scaled\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"Mean of X_train_scaled:\", np.mean(X_train_scaled))\n",
        "print(\"Standard deviation of X_train_scaled:\", np.std(X_train_scaled))\n",
        "\n",
        "print(\"Mean of X_val_scaled:\", np.mean(X_val_scaled))\n",
        "print(\"Standard deviation of X_val_scaled:\", np.std(X_val_scaled))\n",
        "\n",
        "print(\"Mean of X_test_scaled:\", np.mean(X_test_scaled))\n",
        "print(\"Standard deviation of X_test_scaled:\", np.std(X_test_scaled))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_Ir38PPuTvf"
      },
      "source": [
        "**SMOTE (balance classes for label)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDUnZd_9vFP6",
        "outputId": "073dbd9f-ed1a-4db6-f532-1f2495e5d57d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of X_train_scaled: (3171, 6)\n",
            "Shape of y_train: (3171,)\n",
            "\n",
            "Shape of X_train_resampled: (5758, 6)\n",
            "Shape of y_train_resampled: (5758,)\n",
            "\n",
            "Distribution of y_train_resampled:\n",
            "DESIGNATION_BINARY\n",
            "1    2879\n",
            "0    2879\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# prompt: Use SMOTE on X_train and y_train, to fix unbalance in DESIGNATION_BINARY class distribution\n",
        "\n",
        "#!pip install imbalanced-learn\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print()\n",
        "print(\"Shape of X_train_scaled:\", X_train_scaled.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "\n",
        "print()\n",
        "print(\"Shape of X_train_resampled:\", X_train_resampled.shape)\n",
        "print(\"Shape of y_train_resampled:\", y_train_resampled.shape)\n",
        "\n",
        "print()\n",
        "print(\"Distribution of y_train_resampled:\")\n",
        "print(y_train_resampled.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXT5DAo3ujwM"
      },
      "source": [
        "**Baseline model: Logistic**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlJThwn1yGyu",
        "outputId": "3992afe7-21b2-4f7a-857e-679d2058ef68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Performance Metrics (Validation Set):\n",
            "Accuracy: 0.8262\n",
            "Precision: 0.9646\n",
            "Recall: 0.8395\n",
            "F1-score: 0.8977\n",
            "ROC AUC: 0.7665\n"
          ]
        }
      ],
      "source": [
        "# prompt: Fit a Logistic regression on train data sets, validate on the validation data sets. Record performance metrics for further comparison.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "logreg_model = LogisticRegression(random_state=42)\n",
        "logreg_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_val_pred = logreg_model.predict(X_val_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "precision = precision_score(y_val, y_val_pred)\n",
        "recall = recall_score(y_val, y_val_pred)\n",
        "f1 = f1_score(y_val, y_val_pred)\n",
        "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
        "\n",
        "\n",
        "print(\"Logistic Regression Performance Metrics (Validation Set):\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "performance_metrics = {\n",
        "    'model': 'Logistic Regression',\n",
        "    'accuracy': accuracy,\n",
        "    'precision': precision,\n",
        "    'recall': recall,\n",
        "    'f1_score': f1,\n",
        "    'roc_auc': roc_auc\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvvH7dy2uqnw"
      },
      "source": [
        "**Logistic Model: Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArD0l4BOy934",
        "outputId": "5323e99b-ee2f-4d13-d482-bf5e94173a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Logistic Regression Performance Metrics After Tuning (Validation Set):\n",
            "Accuracy: 0.8424\n",
            "Precision: 0.9636\n",
            "Recall: 0.8590\n",
            "F1-score: 0.9083\n",
            "ROC AUC: 0.7682\n",
            "Logistic Regression Performance Metrics After Tuning (Testing set):\n",
            "Accuracy: 0.8294\n",
            "Precision: 0.9596\n",
            "Recall: 0.8476\n",
            "F1-score: 0.9002\n",
            "ROC AUC: 0.7492\n"
          ]
        }
      ],
      "source": [
        "# prompt: Use grid search and cross validation for hyperparameter tuning for the Logistic regression. Record performance metrics.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for Logistic Regression\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
        "    'penalty': ['l1', 'l2'],  # Regularization type\n",
        "    'solver': ['liblinear', 'saga'] # Solvers that support both penalties\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(LogisticRegression(random_state=42, max_iter=1000), param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV to the training data\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "# Get the best hyperparameters and best model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "y_val_pred = best_model.predict(X_val_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "precision = precision_score(y_val, y_val_pred)\n",
        "recall = recall_score(y_val, y_val_pred)\n",
        "f1 = f1_score(y_val, y_val_pred)\n",
        "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
        "\n",
        "\n",
        "print(\"Logistic Regression Performance Metrics After Tuning (Validation Set):\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "performance_metrics_log_val = {\n",
        "    'model': 'Tuned Logistic Regression',\n",
        "    'accuracy': accuracy,\n",
        "    'precision': precision,\n",
        "    'recall': recall,\n",
        "    'f1_score': f1,\n",
        "    'roc_auc': roc_auc\n",
        "}\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_test_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_test_pred)\n",
        "precision = precision_score(y_test, y_test_pred)\n",
        "recall = recall_score(y_test, y_test_pred)\n",
        "f1 = f1_score(y_test, y_test_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "print(\"Logistic Regression Performance Metrics After Tuning (Testing set):\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "performance_metrics = {\n",
        "    'model': 'Tuned Logistic Regression',\n",
        "    'accuracy': accuracy,\n",
        "    'precision': precision,\n",
        "    'recall': recall,\n",
        "    'f1_score': f1,\n",
        "    'roc_auc': roc_auc\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpMraGk65F8R"
      },
      "source": [
        "**Neural Network for binary classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_I2rtfA5OTJ",
        "outputId": "2475a767-2026-4195-d1e8-0e0f336167a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6736 - loss: 0.6053 - val_accuracy: 0.7629 - val_loss: 0.5635\n",
            "Epoch 2/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7757 - loss: 0.5065 - val_accuracy: 0.7717 - val_loss: 0.5215\n",
            "Epoch 3/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7846 - loss: 0.4957 - val_accuracy: 0.7732 - val_loss: 0.5077\n",
            "Epoch 4/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7764 - loss: 0.5003 - val_accuracy: 0.7732 - val_loss: 0.5202\n",
            "Epoch 5/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7820 - loss: 0.4941 - val_accuracy: 0.7938 - val_loss: 0.4965\n",
            "Epoch 6/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7788 - loss: 0.5017 - val_accuracy: 0.7923 - val_loss: 0.4807\n",
            "Epoch 7/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7886 - loss: 0.4838 - val_accuracy: 0.7850 - val_loss: 0.5012\n",
            "Epoch 8/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7887 - loss: 0.4829 - val_accuracy: 0.7850 - val_loss: 0.5039\n",
            "Epoch 9/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7737 - loss: 0.5057 - val_accuracy: 0.7938 - val_loss: 0.4953\n",
            "Epoch 10/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7861 - loss: 0.4825 - val_accuracy: 0.8041 - val_loss: 0.4705\n",
            "Epoch 11/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7887 - loss: 0.4851 - val_accuracy: 0.7938 - val_loss: 0.5052\n",
            "Epoch 12/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7929 - loss: 0.4839 - val_accuracy: 0.7938 - val_loss: 0.4979\n",
            "Epoch 13/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7832 - loss: 0.4984 - val_accuracy: 0.8041 - val_loss: 0.4900\n",
            "Epoch 14/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.4661 - val_accuracy: 0.7938 - val_loss: 0.5000\n",
            "Epoch 15/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7914 - loss: 0.4774 - val_accuracy: 0.8041 - val_loss: 0.4919\n",
            "Epoch 16/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7874 - loss: 0.4970 - val_accuracy: 0.7938 - val_loss: 0.4982\n",
            "Epoch 17/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.4894 - val_accuracy: 0.7938 - val_loss: 0.4951\n",
            "Epoch 18/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7982 - loss: 0.4782 - val_accuracy: 0.7938 - val_loss: 0.4883\n",
            "Epoch 19/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7930 - loss: 0.4843 - val_accuracy: 0.7909 - val_loss: 0.5115\n",
            "Epoch 20/20\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7883 - loss: 0.4895 - val_accuracy: 0.8085 - val_loss: 0.4722\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Neural Network Performance Metrics (Validation Set):\n",
            "Accuracy: 0.8085\n",
            "Precision: 0.9638\n",
            "Recall: 0.8201\n",
            "F1-score: 0.8862\n",
            "ROC AUC: 0.8270\n"
          ]
        }
      ],
      "source": [
        "# prompt: Fit a Neural Network that would be well suited for binary classification on a relatively small dataset. Fit on train data, evaluate on the validation data. Record performance metrics.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Define the model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
        "    keras.layers.Dropout(0.5),  # Add dropout for regularization\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_resampled, y_train_resampled, epochs=20, batch_size=32, validation_data=(X_val_scaled, y_val))\n",
        "\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_val_pred_prob = model.predict(X_val_scaled)\n",
        "y_val_pred = (y_val_pred_prob > 0.5).astype(int) # Convert probabilities to binary predictions\n",
        "\n",
        "# Evaluate the model (validation set)\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "precision = precision_score(y_val, y_val_pred)\n",
        "recall = recall_score(y_val, y_val_pred)\n",
        "f1 = f1_score(y_val, y_val_pred)\n",
        "roc_auc = roc_auc_score(y_val, y_val_pred_prob)\n",
        "\n",
        "\n",
        "print(\"Neural Network Performance Metrics (Validation Set):\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "performance_metrics = {\n",
        "    'model': 'Neural Network',\n",
        "    'accuracy': accuracy,\n",
        "    'precision': precision,\n",
        "    'recall': recall,\n",
        "    'f1_score': f1,\n",
        "    'roc_auc': roc_auc\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DObGpU5-J3a",
        "outputId": "30636d5e-b387-450a-a1ff-7ad8ba8a1f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.5.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.5.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.814410197546022 using {'batch_size': 32, 'epochs': 30, 'model__dropout1': 0.3, 'model__dropout2': 0.2, 'model__units1': 128, 'model__units2': 32}\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow import keras\n",
        "\n",
        "# Define the parameter grid for the neural network\n",
        "param_grid = {\n",
        "    'model__units1': [32, 64, 128],\n",
        "    'model__units2': [16, 32, 64],\n",
        "    'model__dropout1': [0.3, 0.5, 0.7],\n",
        "    'model__dropout2': [0.2, 0.4, 0.6],\n",
        "    'batch_size': [32],\n",
        "    'epochs': [30]\n",
        "}\n",
        "\n",
        "# Function to create and compile the model\n",
        "def create_model(units1, units2, dropout1, dropout2, optimizer='adam'):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(units1, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
        "        keras.layers.Dropout(dropout1),\n",
        "        keras.layers.Dense(units2, activation='relu'),\n",
        "        keras.layers.Dropout(dropout2),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Use KerasClassifier for Scikit-learn compatibility\n",
        "model = KerasClassifier(model=create_model, verbose=0)\n",
        "\n",
        "# Use GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
        "grid_result = grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Print the best parameters and score\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "best_model = grid_result.best_estimator_\n",
        "y_val_pred_prob = best_model.predict_proba(X_val_scaled)\n",
        "y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "# Ensure the labels are binary\n",
        "# y_val = LabelEncoder().fit_transform(y_val)\n",
        "\n",
        "# # Compute metrics\n",
        "# accuracy = accuracy_score(y_val, y_val_pred)\n",
        "# precision = precision_score(y_val, y_val_pred)\n",
        "# recall = recall_score(y_val, y_val_pred)\n",
        "# f1 = f1_score(y_val, y_val_pred)\n",
        "# roc_auc = roc_auc_score(y_val, y_val_pred_prob)\n",
        "\n",
        "# # Print metrics\n",
        "# print(\"Tuned Neural Network Performance Metrics (Validation Set):\")\n",
        "# print(f\"Accuracy: {accuracy:.4f}\")\n",
        "# print(f\"Precision: {precision:.4f}\")\n",
        "# print(f\"Recall: {recall:.4f}\")\n",
        "# print(f\"F1-score: {f1:.4f}\")\n",
        "# print(f\"ROC AUC: {roc_auc:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}