{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxpAq1UchwIJ",
        "outputId": "206d63c7-6320-4d43-b3d7-daea59acef44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import a .csv dataset\n",
        "\n",
        "import pandas as pd\n",
        "mvp_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DL Fall 2024/MSPR predictions/datasets/mvp_train(missing 2018-2019).csv') #Change path if needed\n",
        "print(mvp_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-CfDbUMh7gU",
        "outputId": "44f25b10-7c8d-4f00-d1dc-90481ead2bcd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ATTENDANCE  LOW PARTICIPATION  LATE/MISSING ASSIGNMENTS  \\\n",
            "0           0                  0                         0   \n",
            "1           0                  0                         0   \n",
            "2           0                  0                         0   \n",
            "3           0                  0                         0   \n",
            "4           0                  0                         0   \n",
            "\n",
            "   OTHER ASSIGNMENTS CONCERNS  LOW TEST SCORES  DANGER of UNSATING  \\\n",
            "0                           0                0                   0   \n",
            "1                           0                0                   0   \n",
            "2                           0                0                   0   \n",
            "3                           0                0                   0   \n",
            "4                           0                0                   0   \n",
            "\n",
            "   DESIGNATION_BINARY  \n",
            "0                   1  \n",
            "1                   0  \n",
            "2                   1  \n",
            "3                   1  \n",
            "4                   1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mvp_df.info()"
      ],
      "metadata": {
        "id": "MDyQvr1L7mQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8190ad-0c17-412d-b3ea-a9aea315ea1f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3690 entries, 0 to 3689\n",
            "Data columns (total 7 columns):\n",
            " #   Column                      Non-Null Count  Dtype\n",
            "---  ------                      --------------  -----\n",
            " 0   ATTENDANCE                  3690 non-null   int64\n",
            " 1   LOW PARTICIPATION           3690 non-null   int64\n",
            " 2   LATE/MISSING ASSIGNMENTS    3690 non-null   int64\n",
            " 3   OTHER ASSIGNMENTS CONCERNS  3690 non-null   int64\n",
            " 4   LOW TEST SCORES             3690 non-null   int64\n",
            " 5   DANGER of UNSATING          3690 non-null   int64\n",
            " 6   DESIGNATION_BINARY          3690 non-null   int64\n",
            "dtypes: int64(7)\n",
            "memory usage: 201.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: show distributions for fields in the mvp_df, show distributions in terms of count and percentage\n",
        "\n",
        "# Calculate counts and percentages for each column\n",
        "for col in mvp_df.columns:\n",
        "  print(f\"Distribution for column: {col}\")\n",
        "  counts = mvp_df[col].value_counts()\n",
        "  percentages = (counts / len(mvp_df)) * 100\n",
        "  distribution_df = pd.DataFrame({'Count': counts, 'Percentage': percentages})\n",
        "  print(distribution_df)\n",
        "  print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksymMAIiBEGJ",
        "outputId": "f53f8e3f-6a8f-4cb6-8f49-7f369e734e22"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution for column: ATTENDANCE\n",
            "            Count  Percentage\n",
            "ATTENDANCE                   \n",
            "0            3186   86.341463\n",
            "1             369   10.000000\n",
            "2              88    2.384824\n",
            "3              38    1.029810\n",
            "4               8    0.216802\n",
            "5               1    0.027100\n",
            "--------------------\n",
            "Distribution for column: LOW PARTICIPATION\n",
            "                   Count  Percentage\n",
            "LOW PARTICIPATION                   \n",
            "0                   3157   85.555556\n",
            "1                    445   12.059621\n",
            "2                     73    1.978320\n",
            "3                     15    0.406504\n",
            "--------------------\n",
            "Distribution for column: LATE/MISSING ASSIGNMENTS\n",
            "                          Count  Percentage\n",
            "LATE/MISSING ASSIGNMENTS                   \n",
            "0                          2677   72.547425\n",
            "1                           671   18.184282\n",
            "2                           234    6.341463\n",
            "3                            95    2.574526\n",
            "4                            12    0.325203\n",
            "5                             1    0.027100\n",
            "--------------------\n",
            "Distribution for column: OTHER ASSIGNMENTS CONCERNS\n",
            "                            Count  Percentage\n",
            "OTHER ASSIGNMENTS CONCERNS                   \n",
            "0                            3314   89.810298\n",
            "1                             338    9.159892\n",
            "2                              33    0.894309\n",
            "3                               5    0.135501\n",
            "--------------------\n",
            "Distribution for column: LOW TEST SCORES\n",
            "                 Count  Percentage\n",
            "LOW TEST SCORES                   \n",
            "0                 3162   85.691057\n",
            "1                  448   12.140921\n",
            "2                   74    2.005420\n",
            "3                    6    0.162602\n",
            "--------------------\n",
            "Distribution for column: DANGER of UNSATING\n",
            "                    Count  Percentage\n",
            "DANGER of UNSATING                   \n",
            "0                    3145   85.230352\n",
            "1                     407   11.029810\n",
            "2                      98    2.655827\n",
            "3                      33    0.894309\n",
            "4                       6    0.162602\n",
            "5                       1    0.027100\n",
            "--------------------\n",
            "Distribution for column: DESIGNATION_BINARY\n",
            "                    Count  Percentage\n",
            "DESIGNATION_BINARY                   \n",
            "1                    3378   91.544715\n",
            "0                     312    8.455285\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Split mvp_df into train, validation, and test. Use stratified splitting to maintain class balance across sets.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'TargetVariable' is the column you want to stratify by\n",
        "# Replace 'TargetVariable' with the actual name of your target variable column\n",
        "\n",
        "train_df, temp_df = train_test_split(mvp_df, test_size=0.3, stratify=mvp_df['DESIGNATION_BINARY'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['DESIGNATION_BINARY'], random_state=42)\n",
        "\n",
        "print(\"Train set shape:\", train_df.shape)\n",
        "print(\"Validation set shape:\", val_df.shape)\n",
        "print(\"Test set shape:\", test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yc_A-_6BszT",
        "outputId": "7b77e8f9-5d25-4933-ce75-f3adc9eee151"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (2583, 7)\n",
            "Validation set shape: (553, 7)\n",
            "Test set shape: (554, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Show distributions of DESIGNATION_BINARY in train_df, val_df, and test_df\n",
        "\n",
        "def show_distribution(df, name):\n",
        "    print(f\"Distribution for {name}:\")\n",
        "    counts = df['DESIGNATION_BINARY'].value_counts()\n",
        "    percentages = (counts / len(df)) * 100\n",
        "    distribution_df = pd.DataFrame({'Count': counts, 'Percentage': percentages})\n",
        "    print(distribution_df)\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "show_distribution(train_df, \"train_df\")\n",
        "show_distribution(val_df, \"val_df\")\n",
        "show_distribution(test_df, \"test_df\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75ZxXfnRu4gY",
        "outputId": "61a76680-63cc-47d3-ad5b-0afd7c2c8481"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution for train_df:\n",
            "                    Count  Percentage\n",
            "DESIGNATION_BINARY                   \n",
            "1                    2365   91.560201\n",
            "0                     218    8.439799\n",
            "--------------------\n",
            "Distribution for val_df:\n",
            "                    Count  Percentage\n",
            "DESIGNATION_BINARY                   \n",
            "1                     506   91.500904\n",
            "0                      47    8.499096\n",
            "--------------------\n",
            "Distribution for test_df:\n",
            "                    Count  Percentage\n",
            "DESIGNATION_BINARY                   \n",
            "1                     507   91.516245\n",
            "0                      47    8.483755\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Split train_df into X_train and y_train. Split val_df into X_val and y_val. Split test_df into X_test and y_test.\n",
        "\n",
        "X_train = train_df.drop('DESIGNATION_BINARY', axis=1)\n",
        "y_train = train_df['DESIGNATION_BINARY']\n",
        "\n",
        "X_val = val_df.drop('DESIGNATION_BINARY', axis=1)\n",
        "y_val = val_df['DESIGNATION_BINARY']\n",
        "\n",
        "X_test = test_df.drop('DESIGNATION_BINARY', axis=1)\n",
        "y_test = test_df['DESIGNATION_BINARY']"
      ],
      "metadata": {
        "id": "lrSnJtAqCzxI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Standardize X_train. Then standardize X_val and X_test. Use from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on X_train and transform\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform X_val and X_test using the same scaler\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "veYpwX1HuA2k"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Print mean and std of X_train_scaled, X_val_scaled, and X_test_scaled\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"Mean of X_train_scaled:\", np.mean(X_train_scaled))\n",
        "print(\"Standard deviation of X_train_scaled:\", np.std(X_train_scaled))\n",
        "\n",
        "print(\"Mean of X_val_scaled:\", np.mean(X_val_scaled))\n",
        "print(\"Standard deviation of X_val_scaled:\", np.std(X_val_scaled))\n",
        "\n",
        "print(\"Mean of X_test_scaled:\", np.mean(X_test_scaled))\n",
        "print(\"Standard deviation of X_test_scaled:\", np.std(X_test_scaled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P90Y_LmiuOlt",
        "outputId": "5c520f0d-6dfe-4f96-e61e-01f759ee6cb9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of X_train_scaled: -1.0315661088270909e-17\n",
            "Standard deviation of X_train_scaled: 1.0\n",
            "Mean of X_val_scaled: -0.04772855839980563\n",
            "Standard deviation of X_val_scaled: 0.9650442370384306\n",
            "Mean of X_test_scaled: -0.056699466174357845\n",
            "Standard deviation of X_test_scaled: 0.9104110779138294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Use SMOTE on X_train and y_train, to fix unbalance in DESIGNATION_BINARY class distribution\n",
        "\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print()\n",
        "print(\"Shape of X_train_scaled:\", X_train_scaled.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "\n",
        "print()\n",
        "print(\"Shape of X_train_resampled:\", X_train_resampled.shape)\n",
        "print(\"Shape of y_train_resampled:\", y_train_resampled.shape)\n",
        "\n",
        "print()\n",
        "print(\"Distribution of y_train_resampled:\")\n",
        "print(y_train_resampled.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDUnZd_9vFP6",
        "outputId": "88ac037b-0075-4645-9b19-7034b47b524b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "\n",
            "Shape of X_train_scaled: (2583, 6)\n",
            "Shape of y_train: (2583,)\n",
            "\n",
            "Shape of X_train_resampled: (4730, 6)\n",
            "Shape of y_train_resampled: (4730,)\n",
            "\n",
            "Distribution of y_train_resampled:\n",
            "DESIGNATION_BINARY\n",
            "1    2365\n",
            "0    2365\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Fit a Logistic regression on train data sets, validate on the validation data sets. Record performance metrics for further comparison.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "logreg_model = LogisticRegression(random_state=42)\n",
        "logreg_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_val_pred = logreg_model.predict(X_val_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "precision = precision_score(y_val, y_val_pred)\n",
        "recall = recall_score(y_val, y_val_pred)\n",
        "f1 = f1_score(y_val, y_val_pred)\n",
        "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
        "\n",
        "\n",
        "print(\"Logistic Regression Performance Metrics (Validation Set):\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "performance_metrics = {\n",
        "    'model': 'Logistic Regression',\n",
        "    'accuracy': accuracy,\n",
        "    'precision': precision,\n",
        "    'recall': recall,\n",
        "    'f1_score': f1,\n",
        "    'roc_auc': roc_auc\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlJThwn1yGyu",
        "outputId": "8724b668-3cbc-4cbd-b7c6-cd3f2399e628"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Performance Metrics (Validation Set):\n",
            "Accuracy: 0.8427\n",
            "Precision: 0.9564\n",
            "Recall: 0.8676\n",
            "F1-score: 0.9098\n",
            "ROC AUC: 0.7210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Use grid search and cross validation for hyperparameter tuning for the Logistic regression. Record performance metrics.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for Logistic Regression\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
        "    'penalty': ['l1', 'l2'],  # Regularization type\n",
        "    'solver': ['liblinear', 'saga'] # Solvers that support both penalties\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(LogisticRegression(random_state=42, max_iter=1000), param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV to the training data\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "# Get the best hyperparameters and best model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "y_val_pred = best_model.predict(X_val_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "precision = precision_score(y_val, y_val_pred)\n",
        "recall = recall_score(y_val, y_val_pred)\n",
        "f1 = f1_score(y_val, y_val_pred)\n",
        "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
        "\n",
        "\n",
        "print(\"Logistic Regression Performance Metrics (Validation Set - After Tuning):\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "performance_metrics = {\n",
        "    'model': 'Tuned Logistic Regression',\n",
        "    'accuracy': accuracy,\n",
        "    'precision': precision,\n",
        "    'recall': recall,\n",
        "    'f1_score': f1,\n",
        "    'roc_auc': roc_auc\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArD0l4BOy934",
        "outputId": "8f83eb73-b294-443b-f7c6-772485bec54d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n",
            "Logistic Regression Performance Metrics (Validation Set - After Tuning):\n",
            "Accuracy: 0.8427\n",
            "Precision: 0.9564\n",
            "Recall: 0.8676\n",
            "F1-score: 0.9098\n",
            "ROC AUC: 0.7210\n"
          ]
        }
      ]
    }
  ]
}